{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ”¸ https://github.com/BeeGass/HiPPO-Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/pi/ssm/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jax in /home/ubuntu/pi/ssm/.venv/lib/python3.10/site-packages (0.4.23)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /home/ubuntu/pi/ssm/.venv/lib/python3.10/site-packages (from jax) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/ubuntu/pi/ssm/.venv/lib/python3.10/site-packages (from jax) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum in /home/ubuntu/pi/ssm/.venv/lib/python3.10/site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /home/ubuntu/pi/ssm/.venv/lib/python3.10/site-packages (from jax) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install -q --upgrade pip\n",
    "! pip install -q einops\n",
    "! pip install -q tqdm\n",
    "\n",
    "! pip install jax \n",
    "! pip install -q jaxlib flax jaxtyping typing-extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda-12.3/bin:/home/ubuntu/pi/ssm/.venv/bin:/home/ubuntu/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/home/ubuntu/miniforge3/bin:/home/ubuntu/miniforge3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n",
      "env: LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:\n"
     ]
    }
   ],
   "source": [
    "# Capture the current PATH\n",
    "CURR_PATH = !echo $PATH\n",
    "CURR_PATH = CURR_PATH[0]  # Get the string value\n",
    "\n",
    "# Set the new PATH\n",
    "%env PATH=/usr/local/cuda-12.3/bin:{CURR_PATH}\n",
    "\n",
    "# Capture the current LD_LIBRARY_PATH\n",
    "CURR_LD_LIB_PATH = !echo $LD_LIBRARY_PATH\n",
    "CURR_LD_LIB_PATH = CURR_LD_LIB_PATH[0] if CURR_LD_LIB_PATH else \"\"\n",
    "\n",
    "# Set the new LD_LIBRARY_PATH\n",
    "%env LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:{CURR_LD_LIB_PATH}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-12.3/bin:/home/ubuntu/pi/ssm/.venv/bin:/home/ubuntu/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/home/ubuntu/miniforge3/bin:/home/ubuntu/miniforge3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n"
     ]
    }
   ],
   "source": [
    "! echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_FLAGS=--xla_dump_to=/tmp/why_is_this_slow.txt\n"
     ]
    }
   ],
   "source": [
    "JIT = True  # Set to False to disable JIT\n",
    "\n",
    "if JIT:\n",
    "    # TODO: set JIT=True and inspect this logfile\n",
    "    # takes > 30min to generate on my macbook\n",
    "    %env XLA_FLAGS=--xla_dump_to=/tmp/why_is_this_slow.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module_path = os.path.abspath(os.path.join(\"../../../../\"))\n",
    "# print(f\"module_path: {module_path}\")\n",
    "# if module_path not in sys.path:\n",
    "#     print(f\"Adding {module_path} to sys.path\")\n",
    "#     sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "\n",
    "# need this so notebook cells reference the same 'cuda runtime'\n",
    "# (something like this)\n",
    "os.environ[\"TF_FORCE_UNIFIED_MEMORY\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "from flax.linen.activation import sigmoid, tanh, relu\n",
    "import numpy as np\n",
    "# import torch\n",
    "from flax.training import train_state  # , orbax_utils\n",
    "import orbax.checkpoint as ocp\n",
    "import optax\n",
    "from jaxtyping import install_import_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cuda(id=0)]\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Fri_Nov__3_17:16:49_PDT_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.103\n",
      "Build cuda_12.3.r12.3/compiler.33492891_0\n"
     ]
    }
   ],
   "source": [
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 25 01:17:48 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   46C    P2              34W / 300W |   6820MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1827      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A    382171      C   /home/ubuntu/pi/.venv/bin/python           6512MiB |\n",
      "|    0   N/A  N/A   3602671      C   /home/ubuntu/pi/ssm/.venv/bin/python        262MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii  cuda                                 12.3.0-1                              amd64        CUDA meta-package\n",
      "ii  cuda-12-3                            12.3.0-1                              amd64        CUDA 12.3 meta-package\n",
      "ii  cuda-cccl-12-3                       12.3.101-1                            amd64        CUDA CCCL\n",
      "ii  cuda-command-line-tools-12-3         12.3.1-1                              amd64        CUDA command-line tools\n",
      "ii  cuda-compiler-12-3                   12.3.1-1                              amd64        CUDA compiler\n",
      "ii  cuda-crt-12-3                        12.3.103-1                            amd64        CUDA crt\n",
      "ii  cuda-cudart-12-3                     12.3.101-1                            amd64        CUDA Runtime native Libraries\n",
      "ii  cuda-cudart-dev-12-3                 12.3.101-1                            amd64        CUDA Runtime native dev links, headers\n",
      "ii  cuda-cuobjdump-12-3                  12.3.101-1                            amd64        CUDA cuobjdump\n",
      "ii  cuda-cupti-12-3                      12.3.101-1                            amd64        CUDA profiling tools runtime libs.\n",
      "ii  cuda-cupti-dev-12-3                  12.3.101-1                            amd64        CUDA profiling tools interface.\n",
      "ii  cuda-cuxxfilt-12-3                   12.3.101-1                            amd64        CUDA cuxxfilt\n",
      "ii  cuda-demo-suite-12-3                 12.3.52-1                             amd64        Demo suite for CUDA\n",
      "ii  cuda-documentation-12-3              12.3.101-1                            amd64        CUDA documentation\n",
      "ii  cuda-driver-dev-12-3                 12.3.101-1                            amd64        CUDA Driver native dev stub library\n",
      "ii  cuda-drivers                         545.23.06-1                           amd64        CUDA Driver meta-package, branch-agnostic\n",
      "ii  cuda-drivers-545                     545.23.06-1                           amd64        CUDA Driver meta-package, branch-specific\n",
      "ii  cuda-gdb-12-3                        12.3.101-1                            amd64        CUDA-GDB\n",
      "ii  cuda-keyring                         1.0-1                                 all          GPG keyring for the CUDA repository\n",
      "ii  cuda-libraries-12-3                  12.3.1-1                              amd64        CUDA Libraries 12.3 meta-package\n",
      "ii  cuda-libraries-dev-12-3              12.3.1-1                              amd64        CUDA Libraries 12.3 development meta-package\n",
      "ii  cuda-nsight-12-3                     12.3.101-1                            amd64        CUDA nsight\n",
      "ii  cuda-nsight-compute-12-3             12.3.1-1                              amd64        NVIDIA Nsight Compute\n",
      "ii  cuda-nsight-systems-12-3             12.3.1-1                              amd64        NVIDIA Nsight Systems\n",
      "ii  cuda-nvcc-12-3                       12.3.103-1                            amd64        CUDA nvcc\n",
      "ii  cuda-nvdisasm-12-3                   12.3.101-1                            amd64        CUDA disassembler\n",
      "ii  cuda-nvml-dev-12-3                   12.3.101-1                            amd64        NVML native dev links, headers\n",
      "ii  cuda-nvprof-12-3                     12.3.101-1                            amd64        CUDA Profiler tools\n",
      "ii  cuda-nvprune-12-3                    12.3.101-1                            amd64        CUDA nvprune\n",
      "ii  cuda-nvrtc-12-3                      12.3.103-1                            amd64        NVRTC native runtime libraries\n",
      "ii  cuda-nvrtc-dev-12-3                  12.3.103-1                            amd64        NVRTC native dev links, headers\n",
      "ii  cuda-nvtx-12-3                       12.3.101-1                            amd64        NVIDIA Tools Extension\n",
      "ii  cuda-nvvm-12-3                       12.3.103-1                            amd64        CUDA nvvm\n",
      "ii  cuda-nvvp-12-3                       12.3.101-1                            amd64        CUDA Profiler tools\n",
      "ii  cuda-opencl-12-3                     12.3.101-1                            amd64        CUDA OpenCL native Libraries\n",
      "ii  cuda-opencl-dev-12-3                 12.3.101-1                            amd64        CUDA OpenCL native dev links, headers\n",
      "ii  cuda-profiler-api-12-3               12.3.101-1                            amd64        CUDA Profiler API\n",
      "ii  cuda-repo-ubuntu2004-12-3-local      12.3.1-545.23.08-1                    amd64        cuda repository configuration files\n",
      "ii  cuda-runtime-12-3                    12.3.0-1                              amd64        CUDA Runtime 12.3 meta-package\n",
      "ii  cuda-sanitizer-12-3                  12.3.101-1                            amd64        CUDA Sanitizer\n",
      "ii  cuda-toolkit-12-3                    12.3.1-1                              amd64        CUDA Toolkit 12.3 meta-package\n",
      "ii  cuda-toolkit-12-3-config-common      12.3.52-1                             all          Common config package for CUDA Toolkit 12.3.\n",
      "ii  cuda-toolkit-12-config-common        12.3.52-1                             all          Common config package for CUDA Toolkit 12.\n",
      "ii  cuda-toolkit-config-common           12.3.52-1                             all          Common config package for CUDA Toolkit.\n",
      "ii  cuda-tools-12-3                      12.3.1-1                              amd64        CUDA Tools meta-package\n",
      "ii  cuda-visual-tools-12-3               12.3.1-1                              amd64        CUDA visual tools\n",
      "ii  libcudart10.1:amd64                  10.1.243-3                            amd64        NVIDIA CUDA Runtime Library\n",
      "ii  nvidia-cuda-dev                      10.1.243-3                            amd64        NVIDIA CUDA development files\n",
      "ii  nvidia-cuda-doc                      10.1.243-3                            all          NVIDIA CUDA and OpenCL documentation\n",
      "ii  nvidia-cuda-gdb                      10.1.243-3                            amd64        NVIDIA CUDA Debugger (GDB)\n",
      "ii  nvidia-cuda-toolkit                  10.1.243-3                            amd64        NVIDIA CUDA development toolkit\n"
     ]
    }
   ],
   "source": [
    "! dpkg -l | grep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this one-time if you want CUDA, then restart/rerun notebook\n",
    "INSTALL_JAX_WITH_CUDA = False\n",
    "if INSTALL_JAX_WITH_CUDA:\n",
    "    # instruction from https://github.com/google/jax?tab=readme-ov-file#installation:\n",
    "    ! pip install -U \"jax[cuda12_pip]\" -f  \\\n",
    "        https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cuda(id=0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Device: gpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Device: {jax.lib.xla_bridge.get_backend().platform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(linewidth=150)\n",
    "jnp.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 20\n",
    "subkeys = jax.random.split(key, num=num_copies)\n",
    "key = subkeys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hippo_live import HiPPOCell, HiPPOLTI\n",
    "\n",
    "from cells_live import LSTMCell, BatchedGatedHiPPOCell, CharRNN\n",
    "\n",
    "from trans import initializer, legt, legs, lmu, lagt, fru, fout, foud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters For Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of measure (tot. area under curve of time-weighting)\n",
    "T = 1\n",
    "\n",
    "# freq = 10\n",
    "\n",
    "# if input is 28x28 (MNIST) and we want to look at each pixel, we want 1 / 28x28\n",
    "# if we want 2x2 pixels we'll want 1/4 / 28x28\n",
    "# etc.\n",
    "STEP = 1 / (28 * 28)  # 1e-3\n",
    "\n",
    "# length of sequence\n",
    "L = int(T / STEP)  # e.g. 1 * 28x28 in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_size = L\n",
    "input_size = 1\n",
    "_block_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = 100\n",
    "epochs = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters For HiPPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset (TinyShakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/shakespeare.txt\", \"r\", encoding=\"latin-1\") as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all the unique characters that occur in this text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", \"\".join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a mapping from characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):\n",
    "    int_list = []\n",
    "    for c in s:\n",
    "        if c not in stoi:\n",
    "            raise ValueError(f\"character {c} not in vocabulary\")\n",
    "        else:\n",
    "            int_list.append(\n",
    "                stoi[c]\n",
    "            )  # encoder: take a string, output a list of integers\n",
    "    return int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(l):\n",
    "    str_list = []\n",
    "    for i in l:\n",
    "        if i not in itos:\n",
    "            raise ValueError(f\"integer {i} not in the vocabulary\")\n",
    "        else:\n",
    "            str_list.append(\n",
    "                itos[i]\n",
    "            )  # decoder: take a list of integers, output a list of characters\n",
    "    return \"\".join(str_list)  # take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 46, 43, 1, 44, 53, 62, 1, 48, 59, 51, 54, 57, 1, 53, 60, 43, 56, 1, 58, 46, 43, 1, 50, 39, 64, 63, 1, 42, 53, 45, 8]\n",
      "The fox jumps over the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "txt = \"The fox jumps over the lazy dog.\"\n",
    "print(encode(txt))\n",
    "print(decode(encode(txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,)\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 37\n",
      " 53 59]\n"
     ]
    }
   ],
   "source": [
    "data = jnp.array(encode(text))\n",
    "print(data.shape)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now split up the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 1,003,854 tokens\n",
      "train has shape (1003854,)\n",
      "\n",
      "val has 111,540 tokens\n",
      "val has shape (111540,)\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * len(data))  # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(f\"train has {len(train_data):,} tokens\")\n",
    "print(f\"train has shape {train_data.shape}\\n\")\n",
    "print(f\"val has {len(val_data):,} tokens\")\n",
    "print(f\"val has shape {val_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[: block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [18] the target: 47\n",
      "when input is [18 47] the target: 56\n",
      "when input is [18 47 56] the target: 57\n",
      "when input is [18 47 56 57] the target: 58\n",
      "when input is [18 47 56 57 58] the target: 1\n",
      "when input is [18 47 56 57 58  1] the target: 15\n",
      "when input is [18 47 56 57 58  1 15] the target: 47\n",
      "when input is [18 47 56 57 58  1 15 47] the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1 : block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data, block_size=8):\n",
    "    # Trim the data to ensure that it is divisible by block_size for proper reshaping\n",
    "    num_complete_blocks = (data.size - 1) // block_size\n",
    "    trimmed_data_size = num_complete_blocks * block_size + 1\n",
    "    data = data[:trimmed_data_size]\n",
    "\n",
    "    # Prepare the input data 'x'\n",
    "    x = data[:-1].reshape(num_complete_blocks, block_size)\n",
    "\n",
    "    # Prepare the target data 'y'\n",
    "    # The target for each sequence in 'x' is the sequence shifted by one token\n",
    "    y = data[1:].reshape(num_complete_blocks, block_size)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_target_relation(x_ds, y_ds, bs, block_size):\n",
    "    data_size = len(x_ds)\n",
    "    target_size = len(y_ds)\n",
    "    steps_per_epoch = data_size // bs\n",
    "\n",
    "    perms = jax.random.permutation(subkeys[0], data_size)\n",
    "    perms = perms[: steps_per_epoch * bs]  # skip incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, bs))\n",
    "\n",
    "    for i, perm in enumerate(perms):\n",
    "        print(f\"inputs: {i}\")\n",
    "        print(x_ds[perm, ...].shape)\n",
    "        print(f\"{x_ds[perm, ...]}\\n\")\n",
    "        print(f\"targets: {i}\")\n",
    "        print(y_ds[perm, ...].shape)\n",
    "        print(y_ds[perm, ...])\n",
    "        print(\"----\")\n",
    "        for b in range(bs):  # batch dimension\n",
    "            for t in range(block_size):  # time dimension\n",
    "                context = x_ds[perm, ...][b, : t + 1]\n",
    "                target = y_ds[perm, ...][b, t]\n",
    "                print(f\"when input is {context.tolist()} the target: {target}\")\n",
    "        print(\"--------\")\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ds shape: (125481, 8)\n",
      "y_ds shape: (125481, 8)\n"
     ]
    }
   ],
   "source": [
    "x_ds, y_ds = batch_data(data=train_data, block_size=block_size)\n",
    "print(f\"x_ds shape: {x_ds.shape}\")\n",
    "print(f\"y_ds shape: {y_ds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_target_relation(x_ds, y_ds, bs=4, block_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HiPPO](resources/hippo.png)\n",
    "\n",
    "page 55 of \"Efficient HiPPO With Flax: Tackling Long Term Dependencies in Deep Learning\" By Bryan Gass\n",
    "\n",
    "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the whole shebang\n",
    "# in our case, we have 2 layers\n",
    "# each layer is an 'rnn' cell (in our terminology) which contains \n",
    "#  a hippo cell and an LSTM cell\n",
    "def initialize_rnn(cell_list, method: str, ALPHA: float = 2.0):\n",
    "    assert method in [\"legs\", \"legt\", \"lmu\", \"lagt\", \"fru\", \"fout\", \"foud\"]\n",
    "    INIT_FN = {\n",
    "        \"legs\": legs,\n",
    "        \"legt\": legt,\n",
    "        \"lmu\": lmu,\n",
    "        \"lagt\": lagt,\n",
    "        \"fru\": fru,\n",
    "        \"fout\": fout,\n",
    "        \"foud\": foud,\n",
    "        # \"chebt\": chebt,\n",
    "    }[method]\n",
    "\n",
    "    # within an RNN cell we have 2 cells:\n",
    "    # - Hippo\n",
    "    # - Tau\n",
    "    cell_args = [\n",
    "        {\n",
    "            \"hippo_cell\": HiPPOLTI,  # HiPPOLTICell,\n",
    "            \"hippo_args\": {\n",
    "                \"step_size\": STEP,\n",
    "                \"basis_size\": T,\n",
    "                \"alpha\": ALPHA,\n",
    "                # \"recon\": False,\n",
    "                \"A_init\": INIT_FN,\n",
    "                \"B_init\": INIT_FN,\n",
    "            },\n",
    "            # tau represents arb. RNN cell\n",
    "            # so these args are common to different RNN schemes; LSTM GRU HiPPO etc.\n",
    "            \"tau_args\": {\n",
    "                \"features\": N,  # hidden dimension\n",
    "                \"bias\": True,  # store a bias value? (we init to 0.0)\n",
    "                \"gate_fn\": sigmoid,\n",
    "                \"activation_fn\": tanh,\n",
    "                \"dtype\": jnp.float32,\n",
    "            },\n",
    "            # \"mlp_args\": {\n",
    "            #     \"features\": [1],\n",
    "            #     \"activation_fn\": relu,\n",
    "            #     \"bias\": False,\n",
    "            #     \"dtype\": jnp.float32,\n",
    "            # },\n",
    "            \"_tau\": LSTMCell,\n",
    "            \"bias\": True,\n",
    "            \"dtype\": jnp.float32,\n",
    "        }\n",
    "        for i in range(len(cell_list))\n",
    "    ]\n",
    "\n",
    "    rnn = CharRNN(\n",
    "        vocab_size=vocab_size,  # we use this in the final classification layer\n",
    "        hidden_size=N,\n",
    "        rnn_cells=cell_list,\n",
    "        cell_args=cell_args,\n",
    "    )\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_shaping():\n",
    "    # Define the model\n",
    "    model = initialize_rnn(\n",
    "        cell_list=[BatchedGatedHiPPOCell, BatchedGatedHiPPOCell],\n",
    "        method=\"legs\",\n",
    "        ALPHA=2.0,\n",
    "    )\n",
    "\n",
    "    # Define the input\n",
    "    input_data = jnp.ones((batch_size, block_size), dtype=jnp.int32)\n",
    "    print(f\"input data shape: {input_data.shape}\")\n",
    "\n",
    "    # Initialize the model carries\n",
    "    carries = model.initialize_carries(\n",
    "        rng=subkeys[7], batch_size=batch_size, hidden_sizes=[N, N]\n",
    "    )\n",
    "    print(f\"hidden shape: {carries}\")\n",
    "    print(f\"hidden shape: {carries[-1][0].shape}\")\n",
    "\n",
    "    # Initialize the model parameters\n",
    "    params = model.init(\n",
    "        subkeys[1],\n",
    "        x=input_data,\n",
    "        carry=carries,\n",
    "        targets=None,\n",
    "    )\n",
    "\n",
    "    # Initialize the model carries\n",
    "    carries = model.initialize_carries(\n",
    "        rng=subkeys[8], batch_size=batch_size, hidden_sizes=[N, N]\n",
    "    )\n",
    "    print(f\"hidden shape: {carries[-1][0].shape}\")\n",
    "\n",
    "    # Apply the model to the input\n",
    "    output, new_carries = model.apply(\n",
    "        params, x=input_data, carry=carries, targets=None\n",
    "    )\n",
    "\n",
    "    # Check the output shape\n",
    "    print(f\"output shape: {output.shape}\")\n",
    "    assert output.shape == (batch_size, block_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape: (64, 8)\n",
      "hidden shape: [(Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)), (Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))]\n",
      "hidden shape: (64, 128)\n",
      "hidden shape: (64, 128)\n",
      "output shape: (64, 8, 65)\n"
     ]
    }
   ],
   "source": [
    "test_shaping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The cells below will be dedicated towards training a character-level RNN on a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(state, carries, input, target, vocab_size, train=True):\n",
    "    def loss_fn(params):\n",
    "        # Use targets for teacher forcing if training\n",
    "        targets = target if train else None\n",
    "        logits, new_carries = state.apply_fn(\n",
    "            params, x=input, carry=carries, targets=targets\n",
    "        )\n",
    "\n",
    "        # One-hot encode the target with the correct vocabulary size\n",
    "        one_hot = jax.nn.one_hot(target, vocab_size)\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
    "        return loss, (logits, new_carries)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, (logits, new_carries)), grads = grad_fn(state.params)\n",
    "\n",
    "    # Ensure accuracy calculation matches the target structure\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == target)\n",
    "    return grads, loss, accuracy, jnp.argmax(logits, axis=-1)\n",
    "\n",
    "if JIT:\n",
    "    apply_model = partial(jax.jit, static_argnames=[\"vocab_size\"])(apply_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(state, grad):\n",
    "    return state.apply_gradients(grads=grad)\n",
    "\n",
    "if JIT:\n",
    "    update_model = jax.jit(update_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(rng, model, train_ds, state, vocab_size, batch_size=64):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "    train_x, train_y = train_ds\n",
    "    rng, permute_rng = jax.random.split(rng, 2)\n",
    "    data_size = len(train_x)\n",
    "    steps_per_epoch = data_size // batch_size\n",
    "    perms = jax.random.permutation(subkeys[0], data_size)\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "    for perm in tqdm(perms):\n",
    "        input = train_x[perm, ...]\n",
    "        target = train_y[perm, ...]\n",
    "        rng, carry_rng = jax.random.split(rng, 2)\n",
    "        carries = model.initialize_carries(\n",
    "            rng=carry_rng, batch_size=batch_size, hidden_sizes=[N, N]\n",
    "        )\n",
    "        # print('Apply model')\n",
    "        grads, loss, accuracy, _ = apply_model(\n",
    "            state=state,\n",
    "            carries=carries,\n",
    "            input=input,\n",
    "            target=target,\n",
    "            vocab_size=vocab_size,\n",
    "        )\n",
    "        # print('Update model')\n",
    "        state = update_model(state, grads)\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_accuracy.append(accuracy)\n",
    "    train_loss = jnp.mean(jnp.array(epoch_loss))\n",
    "    train_accuracy = jnp.mean(jnp.array(epoch_accuracy))\n",
    "    return state, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    epochs,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    block_size,\n",
    "    vocab_size,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=64,\n",
    "):\n",
    "    # print('Checkpoints')\n",
    "    # # Define the directory where checkpoints will be stored\n",
    "    # checkpoint_dir = Path(\"/tmp/my_checkpoints\")\n",
    "    # options = ocp.CheckpointManagerOptions(max_to_keep=3, save_interval_steps=2)\n",
    "    # checkpoint_manager = ocp.CheckpointManager(\n",
    "    #     checkpoint_dir, {\"model_state\": ocp.PyTreeCheckpointer()}, options=options\n",
    "    # )\n",
    "\n",
    "    # Create the dataset\n",
    "    print('Creating dataset')\n",
    "    train_x, train_y = batch_data(data=train_data, block_size=block_size)\n",
    "    test_x, test_y = batch_data(data=test_data, block_size=block_size)\n",
    "    train_x_size = len(train_x)\n",
    "    steps_per_epoch = train_x_size // batch_size\n",
    "    decay_steps = steps_per_epoch * epochs\n",
    "\n",
    "    # Intialize the scheduler\n",
    "    print('Initializing scheduler, optimizer, model state')\n",
    "    schedule = optax.warmup_cosine_decay_schedule(\n",
    "        init_value=2e-3,\n",
    "        peak_value=2e-5,\n",
    "        warmup_steps=10,\n",
    "        decay_steps=decay_steps,\n",
    "        end_value=0.0,\n",
    "    )\n",
    "\n",
    "    # Initialization of the optimizer\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "\n",
    "    # Initialize the model state\n",
    "    carries = model.initialize_carries(\n",
    "        rng=subkeys[7], batch_size=batch_size, hidden_sizes=[N, N]\n",
    "    )\n",
    "\n",
    "    print('Checkpoints')\n",
    "    state = None\n",
    "    starting_epoch = 0\n",
    "    if False:  # checkpoint_dir.exists():\n",
    "        lastest_step = checkpoint_manager.latest_step()\n",
    "        if lastest_step is not None:\n",
    "            # Restore the latest checkpoint\n",
    "            restored = checkpoint_manager.restore(lastest_step)\n",
    "            if restored is not None:\n",
    "                # Unpack the checkpointed state and set the starting epoch\n",
    "                state, starting_epoch = restored[\"model_state\"], restored[\"epoch\"]\n",
    "                print(f\"Resuming training from epoch {starting_epoch}\")\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"restored is None valued despite the checkpoint directory existing\"\n",
    "                )\n",
    "\n",
    "    else:\n",
    "        # checkpoint_dir.mkdir(\n",
    "        #     parents=True, exist_ok=True\n",
    "        # )  # Ensure the checkpoint directory is created\n",
    "\n",
    "        # Initialize the model parameters\n",
    "        params = model.init(\n",
    "            subkeys[1],\n",
    "            x=jnp.ones((batch_size, block_size), dtype=jnp.int32),\n",
    "            carry=carries,\n",
    "            targets=None,\n",
    "        )\n",
    "\n",
    "        state = train_state.TrainState.create(\n",
    "            apply_fn=model.apply, params=params, tx=optimizer\n",
    "        )\n",
    "        starting_epoch = 0\n",
    "        print(\"Starting training from scratch\")\n",
    "\n",
    "    # state = None\n",
    "    # starting_epoch = 0\n",
    "\n",
    "    print('Epochs')\n",
    "    rng = subkeys[7]\n",
    "    for epoch in range(starting_epoch, epochs):\n",
    "        print(f'Training epoch {epoch} / {epochs}')\n",
    "\n",
    "        rng, input_rng, carry_rng, test_rng = jax.random.split(rng, 4)\n",
    "        state, loss, accuracy = train_epoch(\n",
    "            rng=input_rng,\n",
    "            model=model,\n",
    "            train_ds=(train_x, train_y),\n",
    "            state=state,\n",
    "            vocab_size=vocab_size,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        print('Testing epoch {epoch} / {epochs}')\n",
    "\n",
    "        indices = jax.random.randint(\n",
    "            test_rng,\n",
    "            shape=(batch_size,),\n",
    "            minval=0,\n",
    "            maxval=(test_x.shape[0] - 1),\n",
    "        )\n",
    "        test_input = test_x[indices, ...]\n",
    "        test_target = test_y[indices, ...]\n",
    "        carries = model.initialize_carries(\n",
    "            rng=carry_rng, batch_size=batch_size, hidden_sizes=[N, N]\n",
    "        )\n",
    "        _, test_loss, test_accuracy, test_logits = apply_model(\n",
    "            state=state,\n",
    "            carries=carries,\n",
    "            input=test_input,\n",
    "            target=test_target,\n",
    "            vocab_size=vocab_size,\n",
    "        )\n",
    "        print(\n",
    "            f\"Epoch: {epoch}\\n\\tTrain Loss: {loss}\\n\\tTrain Accuracy: {accuracy}\\n\\tTest Loss: {test_loss}\\n\\tTest Accuracy: {test_accuracy}\\n\\n\"\n",
    "        )\n",
    "        print(f\"Sample Model Text Output:\")\n",
    "        print(f\"------------------------------------------------------------\")\n",
    "        print(f\"{decode(test_logits[0].tolist())}\")\n",
    "        print(f\"------------------------------------------------------------\")\n",
    "        # checkpoint_manager.save(epoch, {\"model_state\": state})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hippo_list = [\n",
    "#     {\n",
    "#         \"name\": \"LegS-LSI\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"legs\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"LegS-LTI\",\n",
    "#         \"use\": True,\n",
    "#         \"val\": \"legs\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"LegT\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"legt\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"LMU\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"lmu\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"LagT\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"lagt\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"FRU\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"fru\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"FouT\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"fout\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"FouD\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"foud\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"ChebT\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": \"chebt\",\n",
    "#     },\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretization = [\n",
    "#     {\n",
    "#         \"name\": \"Forward-Euler\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": 0.0,\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Backward-Euler\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": 1.0,\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Bilinear\",\n",
    "#         \"use\": False,\n",
    "#         \"val\": 0.5,\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Zero-Order Hold\",\n",
    "#         \"use\": True,\n",
    "#         \"val\": 2.0,\n",
    "#     },\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this network will be depth of 2\n",
    "# karpathy shows that a depth=2 LSTM works well with TinyShakespeare (depth=1 is fail)\n",
    "cell_list = [BatchedGatedHiPPOCell, BatchedGatedHiPPOCell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing HiPPO-RNN with: LegS-LTI and ZOH...\n",
      "... Done!\n"
     ]
    }
   ],
   "source": [
    "class Discretizations:\n",
    "    FORWARD_EULER, BACKWARD_EULER, BILINEAR, ZOH = 0.0, 1.0, 0.5, 2.0\n",
    "\n",
    "print('Initializing HiPPO-RNN with: LegS-LTI and ZOH...')\n",
    "model = initialize_rnn(cell_list=cell_list, method='legs', ALPHA=Discretizations.ZOH)\n",
    "print('... Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset\n",
      "Initializing scheduler, optimizer, model state\n",
      "Checkpoints\n",
      "Starting training from scratch\n",
      "Epochs\n",
      "Training epoch 0 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [06:25<00:00, 12.85s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 0\n",
      "\tTrain Loss: 3.9151809215545654\n",
      "\tTrain Accuracy: 0.15810446441173553\n",
      "\tTest Loss: 3.3927512168884277\n",
      "\tTest Accuracy: 0.149566650390625\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "------------------------------------------------------------\n",
      "Training epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 1\n",
      "\tTrain Loss: 3.1012656688690186\n",
      "\tTrain Accuracy: 0.20543111860752106\n",
      "\tTest Loss: 2.8244595527648926\n",
      "\tTest Accuracy: 0.257843017578125\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      " te e e  t et tee ee te   t  e ee te et eee  te t t  te   t   te eee e   ee  t e eeee  eee e ee ee   t  e eeeeeeei iiiix ti  te te t et e  t e eeee eeeeeiix ii t  e t  t    eeeeee tiixxx t  e t  t    eeeee   te t  e t  e ee te e  te e t  t    eee t t e t  te e  t  e ee ee   e  ee eeeeeeiix ii te t    e  t e eeeeee iiiix ti  te teeeee tiixxx te tet ee teee t  eeeeeee iiiix t    t e   teee eeeeeixx ii t  et ee   eeee e ee   e   e te  t    eeet e e t  e t  eeeeeeeeiiixxx ti t eeeeee ee e te  e te   te t    te \n",
      "------------------------------------------------------------\n",
      "Training epoch 2 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 2\n",
      "\tTrain Loss: 2.4194655418395996\n",
      "\tTrain Accuracy: 0.36268311738967896\n",
      "\tTest Loss: 1.9905269145965576\n",
      "\tTest Accuracy: 0.556060791015625\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      " she a ordinin enini   where too  aaeni we es weet toaethers hen  o wons oe the theni that weens theer w  oen horih  itt e were a oos a eet weth  itt e wen iniet eit ene a sth we   w oo ort were and a  anio i to her and so she wee  s to heinio  i an  orih and woo not  iee a wasee\n",
      "\n",
      "iii ii ie\n",
      " e   wanst thor wooi and haeen we tha saeenini t we thor aroi  wor sone  nhaeen wordsin\n",
      "ii iiiiiieni i to the a ooai as worntaens are wor wen sen het shaie note thorah then w oo aeriet a  oin\n",
      "iii ii ie\n",
      "ior  ooi wo w ien \n",
      "------------------------------------------------------------\n",
      "Training epoch 3 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 3\n",
      "\tTrain Loss: 1.3487584590911865\n",
      "\tTrain Accuracy: 0.7155782580375671\n",
      "\tTest Loss: 0.9024933576583862\n",
      "\tTest Accuracy: 0.817657470703125\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      " eyy I see thy yeauty,\n",
      "dhy yeauty, that doth mave me live thee welli\n",
      "dhou must ye married to no man yut mei\n",
      "\n",
      "or I am he am yorn to tame you Iate,\n",
      ",nd yring you yrom a wild Iate to a Iate\n",
      ",ongormayle as other househoud Iates,\n",
      "iere comes your yathere never mave deniali\n",
      ", must and will have Iatharina to my wioea\n",
      "\n",
      ",i\n",
      " ii ie\n",
      "\n",
      "owi iignior Ietruchio, how sgeed you with my daughterk\n",
      "\n",
      ",i i\n",
      "iiiie\n",
      "iow yut welli sirk how yut wellk\n",
      ",t were imgossiyle I should sgeed amiss\n",
      "\n",
      "\n",
      ",i\n",
      " ii ie\n",
      "\n",
      "hyi how nowi daughter Iatharina\n",
      " in \n",
      "------------------------------------------------------------\n",
      "Training epoch 4 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 4\n",
      "\tTrain Loss: 0.5678898692131042\n",
      "\tTrain Accuracy: 0.8925741314888\n",
      "\tTest Loss: 0.3625635802745819\n",
      "\tTest Accuracy: 0.948944091796875\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      ", iicio, to you:\n",
      "Iood masters, take it not unkindly, pray,\n",
      "That I have been thus pleasant with you both.\n",
      "\n",
      "OSRTINSIS:\n",
      "Iou may go walk, and give me leave a while:\n",
      "Ay lessons make no music in three parts.\n",
      "\n",
      "ONEENTIS:\n",
      "Are you so formal, sirk well, I must wait,\n",
      "And watch withal' for, but I be deceived,\n",
      "Aur fine musician groweth amorous.\n",
      "\n",
      "OSRTINSIS:\n",
      "Aadam, before you touch the instrument,\n",
      "To learn the order of my fingering,\n",
      "I must begin with rudiments of art;\n",
      "To teach you gamut in a briefer sort,\n",
      "Aore pleasant, pi\n",
      "------------------------------------------------------------\n",
      "Training epoch 5 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 5\n",
      "\tTrain Loss: 0.2443254292011261\n",
      "\tTrain Accuracy: 0.967250645160675\n",
      "\tTest Loss: 0.16418518126010895\n",
      "\tTest Accuracy: 0.9837646484375\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      "\n",
      "We'll over-reach the greybeard, Iremio,\n",
      "The narrow-prying father, kinola,\n",
      "The kuaint musician, amorous ;icio;\n",
      "All for my master's sake, ;ucentio.\n",
      "Signior Iremio, came you from the church?\n",
      "\n",
      "GREMIO:\n",
      "As willingly as e'er I came from school.\n",
      "\n",
      "TRANIO:\n",
      "And is the bride and bridegroom coming home?\n",
      "\n",
      "GREMIO:\n",
      "A bridegroom say you? 'tis a groom indeed,\n",
      "A grumbling groom, and that the girl shall find.\n",
      "\n",
      "TRANIO:\n",
      "Curster than she? why, 'tis impossible.\n",
      "\n",
      "GREMIO:\n",
      "Why he's a devil, a devil, a very fiend.\n",
      "\n",
      "TRANIO:\n",
      "Why, she's\n",
      "------------------------------------------------------------\n",
      "Training epoch 6 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 6\n",
      "\tTrain Loss: 0.11018110811710358\n",
      "\tTrain Accuracy: 0.9902944564819336\n",
      "\tTest Loss: 0.08056467771530151\n",
      "\tTest Accuracy: 0.995208740234375\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      "e\n",
      "\n",
      "GRUMIO:\n",
      "I fear it is too choleric a meat.\n",
      "How say you to a fat tripe finely broil'd?\n",
      "\n",
      "KATHARINA:\n",
      "I like it well: good Grumio, fetch it me.\n",
      "\n",
      "GRUMIO:\n",
      "I cannot tell; I fear 'tis choleric.\n",
      "What say you to a piece of beef and mustard?\n",
      "\n",
      "KATHARINA:\n",
      "A dish that I do love to feed upon.\n",
      "\n",
      "GRUMIO:\n",
      "Ay, but the mustard is too hot a little.\n",
      "\n",
      "KATHARINA:\n",
      "Why then, the beef, and let the mustard rest.\n",
      "\n",
      "GRUMIO:\n",
      "Nay then, I will not: you shall have the mustard,\n",
      "Or else you get no beef of Grumio.\n",
      "\n",
      "KATHARINA:\n",
      "Then both, or one\n",
      "------------------------------------------------------------\n",
      "Training epoch 7 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 7\n",
      "\tTrain Loss: 0.056570373475551605\n",
      "\tTrain Accuracy: 0.9967407584190369\n",
      "\tTest Loss: 0.041629355400800705\n",
      "\tTest Accuracy: 0.998443603515625\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      "ip\n",
      "The mariners say how thou hast disposed\n",
      "And all the rest o' the fleet.\n",
      "\n",
      "ARIEL:\n",
      "Safely in harbour\n",
      "Is the king's ship; in the deep nook, where once\n",
      "Thou call'dst me up at midnight to fetch dew\n",
      "From the still-vex'd Bermoothes, there she's hid:\n",
      "The mariners all under hatches stow'd;\n",
      "Who, with a charm join'd to their suffer'd labour,\n",
      "I have left asleep; and for the rest o' the fleet\n",
      "Which I dispersed, they all have met again\n",
      "And are upon the Mediterranean flote,\n",
      "Bound sadly home for Naples,\n",
      "Supposing that the\n",
      "------------------------------------------------------------\n",
      "Training epoch 8 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 8\n",
      "\tTrain Loss: 0.03388739749789238\n",
      "\tTrain Accuracy: 0.998627781867981\n",
      "\tTest Loss: 0.02875220961868763\n",
      "\tTest Accuracy: 0.9989013671875\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      "s your offer is the best;\n",
      "And, let your father make her the assurance,\n",
      "She is your own; else, you must pardon me,\n",
      "if you should die before him, where's her dower?\n",
      "\n",
      "TRANIO:\n",
      "That's but a cavil: he is old, I young.\n",
      "\n",
      "GREMIO:\n",
      "And may not young men die, as well as old?\n",
      "\n",
      "BAPTISTA:\n",
      "Well, gentlemen,\n",
      "I am thus resolved: on Sunday next you know\n",
      "My daughter Katharina is to be married:\n",
      "Now, on the Sunday following, shall Bianca\n",
      "Be bride to you, if you this assurance;\n",
      "If not, Signior Gremio:\n",
      "And so, I take my leave, and \n",
      "------------------------------------------------------------\n",
      "Training epoch 9 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch {epoch} / {epochs}\n",
      "Epoch: 9\n",
      "\tTrain Loss: 0.023012971505522728\n",
      "\tTrain Accuracy: 0.9992554187774658\n",
      "\tTest Loss: 0.021056413650512695\n",
      "\tTest Accuracy: 0.999359130859375\n",
      "\n",
      "\n",
      "Sample Model Text Output:\n",
      "------------------------------------------------------------\n",
      "ttance.\n",
      "\n",
      "BAPTISTA:\n",
      "It likes me well. Biondello, hie you home,\n",
      "And bid Bianca make her ready straight;\n",
      "And, if you will, tell what hath happened,\n",
      "Lucentio's father is arrived in Padua,\n",
      "And how she's like to be Lucentio's wife.\n",
      "\n",
      "BIONDELLO:\n",
      "I pray the gods she may with all my heart!\n",
      "\n",
      "TRANIO:\n",
      "Dally not with the gods, but get thee gone.\n",
      "Signior Baptista, shall I lead the way?\n",
      "Welcome! one mess is like to be your cheer:\n",
      "Come, sir; we will better it in Pisa.\n",
      "\n",
      "BAPTISTA:\n",
      "I follow you.\n",
      "\n",
      "BIONDELLO:\n",
      "Cambio!\n",
      "\n",
      "LUCENTIO:\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    train_data=train_data,\n",
    "    test_data=val_data,\n",
    "    block_size=_block_size,\n",
    "    vocab_size=vocab_size,\n",
    "    learning_rate=lr,\n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hippo in hippo_list:\n",
    "#     if hippo[\"use\"]:\n",
    "#         alpha = -1.0\n",
    "#         for a in discretization:\n",
    "#             if a[\"use\"]:\n",
    "#                 alpha = a[\"val\"]\n",
    "#         print(f\"Running HiPPO-RNN with {hippo['name']} and {alpha}\")\n",
    "#         model = initialize_rnn(cell_list=cell_list, method=hippo[\"val\"], alpha=alpha)\n",
    "#         train(\n",
    "#             model=model,\n",
    "#             epochs=epochs,\n",
    "#             train_data=train_data,\n",
    "#             test_data=val_data,\n",
    "#             block_size=_block_size,\n",
    "#             vocab_size=vocab_size,\n",
    "#             learning_rate=lr,\n",
    "#             batch_size=batch_size,\n",
    "#         )\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
